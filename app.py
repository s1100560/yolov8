from flask import Flask, jsonify
import os
import torch
from torch.serialization import add_safe_globals

app = Flask(__name__)

# ä¿®å¾© PyTorch 2.6 æ¨¡å‹è¼‰å…¥å•é¡Œ
def load_model_fixed(model_path):
    """ä¿®å¾© PyTorch 2.6 å®‰å…¨æ€§é™åˆ¶çš„æ¨¡å‹è¼‰å…¥"""
    try:
        # å°å…¥éœ€è¦çš„é¡åˆ¥
        from ultralytics.nn.tasks import DetectionModel
        from torch.nn.modules.container import Sequential
        
        # æ·»åŠ å®‰å…¨å…¨åŸŸè®Šæ•¸ï¼ˆéŒ¯èª¤è¨Šæ¯è¦æ±‚çš„ï¼‰
        add_safe_globals([DetectionModel, Sequential])
        
        print("ğŸ”§ ä½¿ç”¨å®‰å…¨å…¨åŸŸè®Šæ•¸è¼‰å…¥æ¨¡å‹...")
        
        # ä½¿ç”¨ ultralytics çš„ YOLO è¼‰å…¥ï¼ˆæœƒè‡ªå‹•è™•ç†å…¼å®¹æ€§ï¼‰
        from ultralytics import YOLO
        model = YOLO(model_path)
        
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
        return model, True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None, False

# æ¨¡å‹ç‹€æ…‹
model_loaded = False
model = None

def initialize_model():
    """åˆå§‹åŒ–æ¨¡å‹"""
    global model, model_loaded
    
    model_path = "freshness_fruit_and_vegetables.pt"
    if os.path.exists(model_path):
        print(f"âœ… æ‰¾åˆ°æ¨¡å‹æª”æ¡ˆ: {model_path}")
        model, model_loaded = load_model_fixed(model_path)
    else:
        print("âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
        model_loaded = False

@app.route("/")
def home():
    return {
        "message": "YOLOv8 API é‹è¡Œä¸­", 
        "model_loaded": model_loaded,
        "status": "ready"
    }

@app.route("/test")
def test():
    if model_loaded:
        return {"message": "æ¨¡å‹å·²è¼‰å…¥", "status": "success"}
    else:
        return {"message": "æ¨¡å‹æœªè¼‰å…¥", "status": "error"}

@app.route("/health")
def health():
    return {"status": "healthy", "model_loaded": model_loaded}, 200

@app.route("/load-model")
def load_model_endpoint():
    """æ‰‹å‹•è§¸ç™¼æ¨¡å‹è¼‰å…¥"""
    global model, model_loaded
    if not model_loaded:
        print("ğŸ”„ æ‰‹å‹•è¼‰å…¥æ¨¡å‹ä¸­...")
        initialize_model()
    
    if model_loaded:
        return {"message": "æ¨¡å‹è¼‰å…¥æˆåŠŸ", "status": "success"}
    else:
        return {"message": "æ¨¡å‹è¼‰å…¥å¤±æ•—", "status": "error"}, 500

@app.route("/predict", methods=["POST"])
def predict():
    global model, model_loaded
    
    # ç¬¬ä¸€æ¬¡å‘¼å«æ™‚æ‰è¼‰å…¥æ¨¡å‹
    if not model_loaded:
        initialize_model()
    
    if not model_loaded:
        return {"error": "æ¨¡å‹è¼‰å…¥å¤±æ•—", "status": "error"}, 500
    
    return {"message": "é æ¸¬åŠŸèƒ½æº–å‚™å°±ç·’", "status": "success"}

# æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚ä¸è‡ªå‹•è¼‰å…¥æ¨¡å‹ï¼Œé¿å…å•Ÿå‹•å¤±æ•—
# initialize_model()

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000, debug=False)

